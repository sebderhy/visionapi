{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/sebderhy/visionapi/blob/master/logos/cloud_vision_api.PNG?raw=true\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State-of-the-art computer vision in a single line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cloud Vision API enables developers to integrate state-of-the-art computer vision algorithms in a line of code, without any algorithmic or integration struggle. Below is the list of algorithms currently available in the API:\n",
    "* **Object Detection**: locates and classifies objects in a given picture. <br />\n",
    "    * Option 1: Based on the paper [DETR: End-to-End Object Detection With Transformers](https://alcinos.github.io/detr_page/)\n",
    "    * Option 2: Based on the paper [\"EfficientDet: Scalable and Efficient Object Detection\"](https://arxiv.org/pdf/1911.09070.pdf), ranked #2 as of May 2020 on [COCO's Test set](https://paperswithcode.com/sota/object-detection-on-coco).\n",
    "* **Panoptic Segmentation**: Each pixel is assigned a class label and all object instances are uniquely segmented.\n",
    "    * Based on the paper [DETR: End-to-End Object Detection With Transformers](https://alcinos.github.io/detr_page/)\n",
    "* **Monocular Depth Estimation**:  estimates how far each pixel is from the camera <br />\n",
    "    * Based on the paper [\"From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation\"](https://arxiv.org/pdf/1907.10326v5.pdf), currently state-of-the-art on [KITTI and MIT Datasets](https://paperswithcode.com/task/monocular-depth-estimation), and its [PyTorch implementation](https://github.com/Navhkrin/Bts-PyTorch). A video of the algorithm's results can be found [here](https://www.youtube.com/watch?v=ekezJiGaiQk&feature=youtu.be)\n",
    "    \n",
    "You think that another algorithm should be included in this API? Please tell me about it at sebderhy@gmail.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td><center>Object Detection</center></td><td><center>Depth</center></td></tr>\n",
    "    <tr><td><img src='img_out/efficientdet-d7.png'></td><td><img src='img_out/depth-bts.png'></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read this before you use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Be patient! When you submit an image, the results may take about 20 seconds to arrive\n",
    "* The *semantic segmentation and depth estimation* algorithms will work well **on road pictures** (i.e. pictures taken from a car), because they have been trained on such datasets.\n",
    "* The Background segmentation algorithm will work **only on portraits/selfies**, and is currently **only giving a rough contour** (typically, it will miss the subtilities in hair)\n",
    "* Keep in mind that this is a side-project and not a finished product yet! Although I do my best to keep everything working and resilient, the results may be disappointing, and the server may fail (apologies if that's the case). In any case, please share your feedback with me (sebderhy@gmail.com), so that I can improve it accordingly.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VIZ FOR OBJECT DETECTION\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis_bbox(img_pil, bbox, label=None, score=None,\n",
    "             instance_colors=None, alpha=1., linewidth=2., ax=None, min_score=0.4):\n",
    "    \"\"\"Visualize bounding boxes inside the image.\n",
    "    Args:\n",
    "        img (~numpy.ndarray): An array of shape :math:`(3, height, width)`.\n",
    "            This is in RGB format and the range of its value is\n",
    "            :math:`[0, 255]`. If this is :obj:`None`, no image is displayed.\n",
    "        bbox (~numpy.ndarray): An array of shape :math:`(R, 4)`, where\n",
    "            :math:`R` is the number of bounding boxes in the image.\n",
    "            Each element is organized\n",
    "            by :math:`(y_{min}, x_{min}, y_{max}, x_{max})` in the second axis.\n",
    "        label (~numpy.ndarray): An integer array of shape :math:`(R,)`.\n",
    "            The values correspond to id for label names stored in\n",
    "            :obj:`label_names`. This is optional.\n",
    "        score (~numpy.ndarray): A float array of shape :math:`(R,)`.\n",
    "             Each value indicates how confident the prediction is.\n",
    "             This is optional.\n",
    "        label_names (iterable of strings): Name of labels ordered according\n",
    "            to label ids. If this is :obj:`None`, labels will be skipped.\n",
    "        instance_colors (iterable of tuples): List of colors.\n",
    "            Each color is RGB format and the range of its values is\n",
    "            :math:`[0, 255]`. The :obj:`i`-th element is the color used\n",
    "            to visualize the :obj:`i`-th instance.\n",
    "            If :obj:`instance_colors` is :obj:`None`, the red is used for\n",
    "            all boxes.\n",
    "        alpha (float): The value which determines transparency of the\n",
    "            bounding boxes. The range of this value is :math:`[0, 1]`.\n",
    "        linewidth (float): The thickness of the edges of the bounding boxes.\n",
    "        ax (matplotlib.axes.Axis): The visualization is displayed on this\n",
    "            axis. If this is :obj:`None` (default), a new axis is created.\n",
    "    Returns:\n",
    "        ~matploblib.axes.Axes:\n",
    "        Returns the Axes object with the plot for further tweaking.\n",
    "    from: https://github.com/chainer/chainercv\n",
    "    \"\"\"\n",
    "\n",
    "    if label is not None and not len(bbox) == len(label):\n",
    "        raise ValueError('The length of label must be same as that of bbox')\n",
    "    if score is not None and not len(bbox) == len(score):\n",
    "        raise ValueError('The length of score must be same as that of bbox')\n",
    "\n",
    "    # Returns newly instantiated matplotlib.axes.Axes object if ax is None\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        # ax = fig.add_subplot(1, 1, 1)\n",
    "#         h, w, _ = img.shape\n",
    "        w, h = img_pil.size\n",
    "        w_ = w / 60.0\n",
    "        h_ = w_ * (h / w)\n",
    "        fig.set_size_inches((w_, h_))\n",
    "        ax = plt.axes([0, 0, 1, 1])\n",
    "#     ax.imshow(img.astype(np.uint8))\n",
    "    ax.imshow(img_pil)\n",
    "    ax.axis('off')\n",
    "    # If there is no bounding box to display, visualize the image and exit.\n",
    "    if len(bbox) == 0:\n",
    "        return fig, ax\n",
    "\n",
    "    if instance_colors is None:\n",
    "        # Red\n",
    "        instance_colors = np.zeros((len(bbox), 3), dtype=np.float32)\n",
    "        instance_colors[:, 0] = 51\n",
    "        instance_colors[:, 1] = 51\n",
    "        instance_colors[:, 2] = 224\n",
    "    instance_colors = np.array(instance_colors)\n",
    "\n",
    "    for i, bb in enumerate(bbox):\n",
    "        if score[i]<min_score: \n",
    "            continue\n",
    "\n",
    "        xy = (bb[0], bb[1])\n",
    "        height = bb[3] - bb[1]\n",
    "        width = bb[2] - bb[0]\n",
    "        color = instance_colors[i % len(instance_colors)] / 255\n",
    "        ax.add_patch(plt.Rectangle(\n",
    "            xy, width, height, fill=False,\n",
    "            edgecolor=color, linewidth=linewidth, alpha=alpha))\n",
    "\n",
    "        caption = []\n",
    "        caption.append(obj_list[label[i]])\n",
    "        if(len(score) > 0):\n",
    "            sc = int(score[i]*100)\n",
    "            caption.append('{}%'.format(sc))\n",
    "\n",
    "        if len(caption) > 0:\n",
    "            face_color = np.array([225, 51, 123])/255\n",
    "            ax.text(bb[0], bb[1],\n",
    "                    ': '.join(caption),\n",
    "                    fontsize=12,\n",
    "                    color='black',\n",
    "                    style='italic',\n",
    "                    bbox={'facecolor': face_color, 'edgecolor': face_color, 'alpha': 1, 'pad': 0})\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltfigure2img(fig ,ax):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi = 100)\n",
    "    plt.close(fig) \n",
    "    buf.seek(0)\n",
    "    img_pil_out = (Image.open(buf)).copy()\n",
    "    buf.close()\n",
    "    return img_pil_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "            'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "            'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '', 'handbag', 'tie',\n",
    "            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "            'skateboard', 'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "            'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "            'cake', 'chair', 'couch', 'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n",
    "            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "            'refrigerator', '', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "            'toothbrush']\n",
    "\n",
    "def parse_objdet_response(r):\n",
    "    rois = eval(r.json()['rois'])\n",
    "    rois = np.array(rois)\n",
    "\n",
    "    class_ids = eval(r.json()['class_ids'])\n",
    "    class_ids = np.array(class_ids)\n",
    "\n",
    "    scores = eval(r.json()['scores'])\n",
    "    scores = np.array(scores)\n",
    "    return rois, class_ids, scores\n",
    "\n",
    "def generate_objdet_img(r, img_in):\n",
    "    rois, class_ids, scores = parse_objdet_response(r)    \n",
    "    fig, ax = vis_bbox(img_pil=img_in, bbox=rois,\n",
    "                   label=class_ids, score=scores)\n",
    "    img_out = pltfigure2img(fig,ax)\n",
    "    img_out = img_out.resize(img_in.size)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BG = 'https://img.theculturetrip.com/768x432/wp-content/uploads/2018/01/webp-net-compress-image-45.jpg'\n",
    "def viz_out(model, img_in, img_out, url_bg=URL_BG):\n",
    "    if model[0] == 'binseg':\n",
    "        response = requests.get(url_bg)\n",
    "        bg = Image.open(BytesIO(response.content))\n",
    "        bg2 = bg.resize(img_in.size)\n",
    "        img_out2=Image.composite(img_in, bg2, img_out)\n",
    "    else:\n",
    "        img_out2 = img_out\n",
    "    return img_out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: call from URL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Image URL you want to test below, and click on process. Both the input and output will be displayed. \n",
    "\n",
    "**Be patient, the results can take ~20 seconds to appear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_placeholder = widgets.Text(\n",
    "    placeholder='URL of an image',\n",
    "    value = 'https://www.go-telaviv.com/images/driving-in-israel-tel-aviv-traffic-jam1.jpg',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl_url = widgets.Output()\n",
    "out_pl_url.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl_url_2 = widgets.Output()\n",
    "out_pl_url_2.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list_url = widgets.Dropdown(\n",
    "    options=[('Super-resolution', ['superres', 'superres-2b']),\n",
    "             ('Style Transfer 1', ['styletransfer', 'styletransf-1']),\n",
    "             ('Style Transfer 2', ['styletransfer', 'styletransf-2']),\n",
    "             ('Style Transfer 3', ['styletransfer', 'styletransf-3']),\n",
    "             ('Semantic Segmentation', ['semseg', 'semseg-3']),\n",
    "             ('Depth', ['depth', 'depth-bts']),\n",
    "             ('Object Detection', ['objdet', 'efficientdet-d4']),\n",
    "             ('Background Extraction', ['binseg', 'binseg-3'])],\n",
    "    value=['semseg', 'semseg-3'],\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run_url = widgets.Button(description='Process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_status_url = widgets.Label()\n",
    "lbl_status_url.value = 'waiting for user input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_process_url(change):\n",
    "    out_pl_url.clear_output()\n",
    "    out_pl_url_2.clear_output()\n",
    "    lbl_status_url.value = 'loading input image...'\n",
    "    response = requests.get(url_placeholder.value)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    lbl_status_url.value = 'Image loaded (see below). Processing...'\n",
    "    with out_pl_url: display(img)\n",
    "    r = URLImgAPICall(url_placeholder.value, f'{models_list_url.value[0]}/{models_list_url.value[1]}/')\n",
    "    if models_list_url.value[0] != 'objdet':\n",
    "        img_out = response2img(r)\n",
    "        img_out = viz_out(models_list_url.value, img, img_out)\n",
    "    else: \n",
    "        img_out = generate_objdet_img(r, img)\n",
    "    with out_pl_url_2: display(img_out)\n",
    "    lbl_status_url.value = 'Here is the output image !'\n",
    "\n",
    "btn_run_url.on_click(on_click_process_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c7c47a447945de99668a6adb03a551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Choose your algorithm'), Dropdown(index=4, options=(('Super-resolution', ['superre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.Label('Choose your algorithm'), models_list_url,\n",
    "              widgets.Label('Write your image URL'), url_placeholder, \n",
    "              widgets.Label('Click below to process the image'), btn_run_url, \n",
    "              lbl_status_url, out_pl_url, out_pl_url_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Import local picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl = widgets.Output()\n",
    "out_pl.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl2 = widgets.Output()\n",
    "out_pl2.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = widgets.Dropdown(\n",
    "    options=[('Super-resolution', ['superres', 'superres-2b']),\n",
    "             ('Style Transfer 1', ['styletransfer', 'styletransf-1']),\n",
    "             ('Style Transfer 2', ['styletransfer', 'styletransf-2']),\n",
    "             ('Style Transfer 3', ['styletransfer', 'styletransf-3']),\n",
    "             ('Semantic Segmentation', ['semseg', 'semseg-3']),\n",
    "             ('Depth', ['depth', 'depth-bts']),\n",
    "             ('Object Detection', ['objdet', 'efficientdet-d4']),\n",
    "             ('Background Extraction', ['binseg', 'binseg-3'])],\n",
    "    value=['objdet', 'efficientdet-d4'],\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run = widgets.Button(description='Process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_status = widgets.Label()\n",
    "lbl_status.value = 'waiting for user input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_process(change):\n",
    "    out_pl.clear_output()\n",
    "    out_pl2.clear_output()\n",
    "    lbl_status.value = 'loading input image...'\n",
    "    img = Image.open(BytesIO(btn_upload.data[-1]))\n",
    "    with out_pl: display(img)\n",
    "    lbl_status_url.value = 'Image loaded (see below). Processing...'\n",
    "    r = pilImgAPICall(img, f'{models_list.value[0]}/{models_list.value[1]}/')\n",
    "    if models_list.value[0] != 'objdet':\n",
    "        img_out = response2img(r)\n",
    "        img_out = viz_out(models_list_url.value, img, img_out)\n",
    "    else: \n",
    "        img_out = generate_objdet_img(r, img)\n",
    "    with out_pl2: display(img_out)\n",
    "    lbl_status.value = 'Here is the output image !'\n",
    "\n",
    "btn_run.on_click(on_click_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload your image below, and click on process. Both the input and output will be displayed. \n",
    "\n",
    "**Be patient, the results can take ~20 seconds to appear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171b77cf46444f6d943e9b8d4b9ba1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Choose your algorithm'), Dropdown(index=6, options=(('Super-resolution', ['superre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 10.800711870193481\n"
     ]
    }
   ],
   "source": [
    "widgets.VBox([widgets.Label('Choose your algorithm'), models_list,\n",
    "              widgets.Label('Choose your image'), btn_upload, \n",
    "              widgets.Label('Click below to process the image'), btn_run, \n",
    "              lbl_status, out_pl, out_pl2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
